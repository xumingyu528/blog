---
title: CSAPP-虚拟内存
permalink: /CSAPP-虚拟内存
category: 操作系统
tag: 
  - CSAPP
  - 操作系统
author: xmy
---





## 物理和虚拟寻址

计算机系统的主存被组织成一个由 M 个连续的字节大小的单元组成的数组。每个字节都有一个唯一的__物理地址(Physical Address, PA)__，第一个字节的地址为0，依次向上增长。CPU访问内存最自然的方式就是使用物理地址，这种方式称为__物理寻址(physical addressing)__。  

* 早起的 PC 使用物理寻址，现在很多数字信号处理器、嵌入式微控制器、Cray这一类超级计算机仍然会使用物理寻址
* 现代处理器大多使用__虚拟寻址(virtual addressing)__的寻址形式
  * CPU 通过生成一个__虚拟地址(Virtual Address, VA)__来访问主存
  * 这个虚拟地址被送到内存之前先被转换成适当的物理地址，这个转换任务叫做__地址翻译(address translation)__
  * CPU 芯片上的 __内存管理单元(Memory Management Unit, MMU)__ 利用存放在主存中的查询表来动态翻译虚拟地址，该表内容由操作系统管理









## 地址空间

__地址空间(address space)__ 是一个非负整数地址的有序集合：`{0,1,2,...}`  

* 如果地址空间中的整数是连续的，那么它就是一个__线性地址空间(linear address space)__
* 在一个带虚拟内存的系统中，CPU 从一个有 $N=2^n$ 个地址的地址空间中生成虚拟地址，这个地址空间称为__虚拟地址空间(virtual address space)__：`{0,1,2, ... ,N-1}`
* 一个地址空间的大小是由表示最大地址所需要的位来描述的
   * 例如 $N=2^n$ 个地址的虚拟地址空间就叫做一个 n 位地址空间，现代系统通常支持 32 位或者 64 位虚拟地址空间
* 一个系统还有一个__物理地址空间(physical address space)__，对应于系统中物理内存的 M 个字节：`{0,1,2, ... ,M-1}`



地址空间区分了数据对象（字节）和它们的属性（地址）。

* 每个数据对象有多个独立的地址，诶中每个地址都选自一个不同的地址空间
* 主存中的每字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址





## 虚拟内存作为缓存的工具

虚拟内存被组织为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组。每字节都有一个唯一的虚拟地址，作为到数组的索引。  

磁盘上数组的内容被缓存在主存中。和存储器层次结构中其它缓存一样，磁盘（较低层）上的数据被分割成块，这些块作为磁盘和主存（较高层）之间的传输单元。

* VM 系统通过将虚拟内存分割为称为 __虚拟页(Virtual Page, VP)__ 的大小固定的块来处理这个问题。每个虚拟页的大小为 $P=2^p$ 字节。
* 物理内存被封为 __物理页(Physical Page, PP)__，大小也为 P 字节，物理页也被称为 __页帧(page frame)__。



在任意时刻，虚拟页面的集合都分为三个不相交的子集：

* 未分配的：VM 系统还未分配的页，未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间
* 缓存的：当前已缓存在物理内存中的已分配页
* 未缓存的：未缓存在物理内存中的已分配页



### DRAM 缓存的组织结构

* DRAM 比 SRAM 慢10倍左右，磁盘比 DRAM 要慢 100000 倍左右。因此，DRAM 缓存不命中比 SRAM 缓存的不命中要昂贵得多。
* 而且，从磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢大约 100000 倍。
* 由于大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是 4KB ~ 2MB。
* DRAM 缓存是全相联的，任何虚拟页都可以放置在任何物理页
* 由于替换错了虚拟页的处罚非常高，操作系统对 DRAM 缓存使用了比 硬件对 SRAM 缓存更复杂精密的替换算法

* 由于对磁盘的访问时间很长，DRAM 缓存总是使用写回，而不是直写





### 页表

页表是用来判定虚拟页是否缓存在 DRAM 中的某个地方，如果有缓存需要确定虚拟页存放在哪个物理页中，如果未缓存，必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。  

页表功能由软硬件联合提供，包括操作系统、MMU（内存管理单元）中的地址翻译硬件和一个存放在物理内存中的__页表(page table)__的数据结构，

* 每次地址翻译硬件讲一个虚拟地址转换为物理地址时，都会读取页表

* 操作系统负责维护页表的内容、在磁盘和 DRAM 之间来回传送页

* 页表就是一个__页表条目(Page Table Entry, PTE)__的数组。

* 虚拟地址空间中每个页在页表中一个固定偏移量处都有一个PTE

* 假设 PTE 由一个有效位和 n 位地址字段组成：

  * 有效位表明了 VP 当前是否被缓存在 DRAM中
  * 如果有缓存，地址位就表明了 DRAM 中相应 PP 的起始位置

  



### 页命中

CPU 要读取包含在某 VP 中的数据时，此 VP 被缓存在 DRAM 中，地址翻译硬件将虚拟地址作为一个索引来定位对应的 PTE，并从内存中读取它，PTE 中的物理内存地址，构造出要读取的数据物理地址。



### 缺页

DRAM 缓存不命中称为 __缺页(page fault)__。缺页处理流程：

1. CPU 引用了 VP 中的数据，该 VP 未缓存在 DRAM 中
2. 地址翻译硬件从内存中读取 VP 对应的 PTE ，从有效位推断出此 VP 未被缓存，触发一个缺页异常
3. 缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页
   1. 如果此牺牲页中内容未被修改，内核修改牺牲页对应 PTE 有效位
   2. 如果此牺牲页中内容被修改过，内核就会将它复制回磁盘，然后修改牺牲页对应 PTE 有效位
4. 内核从磁盘复制 VP 到内存中一个 PP，更新 PTE，然后从异常处理程序返回
5. 异常处理程序返回时，会重新启动导致缺页的指令，该指令会把导致缺页的 VP 重发送到地址翻译硬件
6. 地址翻译硬件按照页命中流程正常处理



虚拟内存是在20世纪60年代早期发明的，在 SRAM 产生之前，因此许多术语与 SRAM 缓存不同

* 块被称为页
* 在磁盘和内存之间传送页的互动叫做__交换(swapping)__或者__页面调度(paging)__
* 页从磁盘换入(或者页面调入)DRAM 、从 DRAM 换出(或者页面调出)磁盘
* 当不命中发生时，才换入页面的这种策略称为__按需页面调度(demand paging)__







### 分配页面

当操作系统分配一个新的虚拟内存页，例如调用 malloc，会在磁盘上创建对应空间，然后更新 PTE，使 PTE 指向磁盘上新创建的页面。



### 局部性(locality)

尽管整个运行过程中程序引用的不同页面的总数可能超过物理内存总的大小，但是局部性原则保证了在任意时刻，程序将趋向于在一个较小的__活动页面(active page)__集合上工作，这个集合叫做__工作集(working set)__ 或者__常驻集合(resident set)__，将工作集页面调度到内存中之后，接下来对工作集的引用将导致命中，不会产生磁盘流量。  

但是当工作集大小超出物理内存的大小，那么程序将产生__抖动(thrashing)__ 状态，页面将频繁从内存和磁盘中换进换出，速度变得很慢。  

Linux 可以利用 `getrusage` 函数监测缺页的数量。







## 虚拟内存作为内存管理的工具

操作系统为每个进程提供了一个独立的页表，因而每个进程都有一个独立的虚拟地址空间，按需页面调度和独立的虚拟地址空间结合，简化了链接、加载、代码和数据共享，以及应用程序的内存分配：

* 简化链接：独立的地址空间允许每个进程的内存映像使用相同的基本格式，不管实际代码和数据存放在物理内存的何处。简化了链接器的设计和实现，允许链接器生成完全链接的可执行文件，这些可执行文件独立于内存中代码和数据的最终位置
* 简化加载：虚拟内存使得容易向内存中加载可执行文件和共享对象文件。把目标文件中 .text 和 .data 加载到一个新进程中，Linux 加载器为代码和数据段分配虚拟页，把它们标记为无效的(未被缓存的)，页面被初次引用时，虚拟内存按需自动调入页面。
  * 将一组连续的虚拟页映射到任意一个文件的任意位置的表示法称为__内存映射(memory mapping)__。
  * Linux 提供了一个 mmap 的系统调用，允许应用程序自己做内存映射
* 简化共享：操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本。
* 简化内存分配：虚拟内存向用户进程提供一个简单的分配额外内存的机制，用户进程的程序要求额外的堆空间时，例如 Linux 的 malloc 系统调用，操作系统分配一个适当数字个连续的虚拟内存页面，并将它们映射到物理内存中任意位置的适当数字个任意的物理页面。这些物理内存无需是连续的物理内存页面，可以随机分散在物理内存中。







## 虚拟内存作为内存保护的工具

任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问。

* 不应该允许用户进程修改它的只读代码段
* 不应该允许它修改内核中的代码和数据结构
* 不应该允许它读写其它进程的私有内存
* 不允许它修改任何与其他进程共享的虚拟页面，除非所有的共享者都显式地允许它修改（例如调用明确的进程间通信系统调用）



利用地址翻译机制和 PTE ，可以很自然的扩展出一种访问控制，在 PTE 中添加一些额外的许可位来控制对虚拟页面内容的访问，例如增加三个许可位

* SUP：是否必须运行在内核模式才能访问该页，用户进程只能访问 SUP 标示为0的页面
* READ：页面的读权限
* WRITE：页面的写权限

如果一条指令违反了这些许可，CPU 触发一个一般保护故障，将控制传递给内核中的异常处理程序，Linux shell 一般将这种异常报告为“段错误(segmentation fault)”







## 地址翻译



形式上来说，地址翻译是一个 N 元素的虚拟地址空间(VAS)中的元素和一个 M 元素的物理地址空间(PAS)中元素之间的映射，
$$
MAP: VAS \rightarrow PAS \cup \emptyset
$$


CPU 中的一个控制寄存器，__页表基址寄存器(Page Table Base Register, PTBR)__ 指向当前页表。n 位的虚拟地址包含两个部分：一个 p 位的__虚拟页面偏移(Virtual Page Offset,VPO)__ 和一个 (n-p) 位的__虚拟页号(Virtual Page Number,VPN)__。MMU 利用 VPN 来选择适当的 PTE，例如 VPN0 选择 PTE0，VPN1 选择 PTE1.将页表条目中的__物理页号(Physical Page Number, PPN)__ 和 虚拟地址中的 VPO 串联起来，得到相应的物理地址。由于物理和虚拟页面都是 P 字节的，所以__物理页面偏移(Physical Page Offset, PPO)__ 和 VPO 是相同的。



### 结合高速缓存和虚拟内存

在既使用虚拟内存又使用 SRAM 高速缓存的系统中，大多数系统是使用物理寻址的。使用物理寻址，多个进程在同时在高速缓存中有存储块和共享来自相同虚拟页面的块称为很简单的事情，高速缓存无需处理保护问题，因为访问权限的检查是地址翻译过程的一部分。

* CPU 请求一个 VA
* MMU 在高速缓存中查找 PTE 条目
  * 如果命中返回，继续查找对应 PA
  * 如果未命中，去内存中查找 PTE ，加载 PTEA 到告诉缓存，然后返回继续查找 PA，内存中请求需要及时到几百个周期
* MMU 根据 PTE 在高速缓存中查找 PA
  * 如果命中返回，CPU 继续执行指令
  * 如果未命中，去内存中查找数据，加载到高速缓存，再返回给 CPU



### 利用 TLB 加速地址翻译

CPU 请求的虚拟地址，MMU 必须查阅 PTE，如果在内存中代价非常高，如果恰好在高速缓存中，开销就只有1到2个周期，许多系统都试图消除即使是这样的开销，它们在 MMU 中包括了一个关于 PTE 的小的缓存，称为__翻译后备缓冲器(Translation Lookaside Buffer, TLB)__。  

TLB 是一个小的、虚拟寻址的缓存，每一行都保存着一个由单个 PTE 组成的块。

* TLB 通常有高度的相联度
* 用于组选择和行匹配的索引和标记字段是从虚拟地址中的虚拟页号中提取出来的
* 如果 TLB 有 $T=2^t$ 个组，那么__TLB索引(TLBI)__ 是由 VPN 的 t 个最低位组成的，而 __TLB标记(TLBT)__ 是由 VPN 中剩余的位组成的



TLB 命中时，由于所有地址翻译步骤都是在芯片 MMU 中执行的，因此非常快。如果 TLB 未命中，MMU 必须从 L1 缓存中取出相应的 PTE，新取出的 PTE 存放在 TLB 中，可能会覆盖一个已存在的条目。







### 多级页表



用来压缩页表的常用方法是使用层次结构的页表。  

以两级页表为例，一级页表中每个 PTE 负责映射虚拟地址空间中一个 4MB 的片(chunk)，这里每一个片都是由 1024 个连续的页面组成的。PTE0 映射第一片，PTE1 映射第二片，假设4GB的地址空间，1024个PTE就足够覆盖整个空间。  

如果片 i 中的每个页面都未被分配，那么一级 PTEi 就为空。如果片 i 中至少有一个页是已分配了的，那么一级 PTEi 就指向一个二级页表的基址。  

二级页表中的每个 PTE 都负责映射一个 4KB 的虚拟内存页面，就像我们查看只有一级的页表一样。注意，使用4字节的PTE，每个一级和二级页表都是4KB字节，刚好和一个页面的大小是一样的。  

这种方法减少了内存要求：  

* 如果一级页表中的一个 PTE 是空的，那么相应的二级页表就根本不会存在
* 只有一级页表才需要总是在主存中；虚拟内存系统可以在需要时创建、页面调入或调出二级页表，这就减少了主存的压力；只有最经常使用的二级页表才需要缓存在主存中。



使用 k 级页表层次结构的地址翻译，虚拟地址被划分为 k 个 VPN 和 1 个 VPO。每个 VPNi 都是一个到第 i 级页表的索引，其中 $1 \leq i \leq k$ 。第 j 级页表中的每个 PTE，$1 \leq j \leq k-1$ ，都指向第 j+1 级的某个页表的基址。第 k 级页表中的每个 PTE 包含某个物理页面的 PPN，或者一个磁盘块地址。为了构造物理地址，在能够确定 PPN 之前，MMU 必须访问 k 个 PTE。对于只有一级的页表结构，PPO 和 VPO 是相同的。  









### 示例：端到端的地址翻译

示例运行在一个 TLB 和 L1 d-cache 的小系统上，假设如下：

* 内存按字节寻址的
* 内存访问是针对 1 字节的字的（不是4字节的字）
* 虚拟地址是 14 位长的（n=14）
* 物理地址是 12 位长的（m=12）
* 页面大小是 64 字节（P=64）
* TLB 是四路组相联的，总共有 16 个条目
* L1 d-cache 是物理寻址、直接映射的，行大小为 4 字节，而总共有 16 个组

划分虚拟地址和物理地址的位：

* TLB：TLB 是利用 VPN 的位进行虚拟寻址的。因为 TLB 有4个组，所以 VPN 的低 2 位就作为组索引(TLBI)。VPN 中剩下的高 6 位就作为标记(TLBT)，用来区分可能映射到同一个 TLB 组的不同的 VPN。
* 页表：单级页表设计，一共有 $2^8 = 256$ 个页表条目（PTE）。
* 高速缓存：直接映射的缓存是通过物理地址中的字段来寻址的。每个块都是 4字节，所以物理地址的低 2 位作为块偏移（CO）。因为有 16 组，所以接下来 4 位用来表示组索引（CI），剩下的 6 位作为标记（CT）。





## Intel Core i7 / Linux 内存系统



Core i7 的底层 Haswell 为体系结构允许完全的 64 位虚拟和物理地址空间，而现在的 Core i7 实现支持 48位(256TB)虚拟地址空间和52位(4PB)物理地址空间，还有一个兼容模式，支持32位(4GB)虚拟和物理地址空间。  

Core i7 内存系统主要部分：

* 处理器封装(processor package)包括四个核、一个大的所有核共享的 L3 高速缓存、以及一个 DDR3 内存控制器
* 每个核包含一个层次结构的 TLB 、一个层次结构的数据和指令高速缓存，以及一组快速的点到点链路，这种链路基于 QuickPath 技术，为了让一个核与其它核和外部 I/O 桥直接通信。
* TLB 是虚拟寻址的，是四路组相联的。
* L1、L2、L3 高速缓存是物理寻址的，块大小为 64 字节
* L1、L2 是8路组相联的
* L3 是 16 路组相联的
* 页大小可以在启动时被配置为 4KB 或 4MB，Linux 使用的是 4KB 的页



### Core i7 地址翻译



流程：

* CPU 产生虚拟地址，发送 VPN 到 MMU 查找 L1 TLB，发送 VPO 到 L1 缓存
* L1 TLB 命中：根据 PPN、PPO 找到对应物理地址 PA
* L1 TLB 不命中：在页表中查找
  * i7 采用四层页表层次结构，每个页表大小4KB。
  * CR3 寄存器会指向第一级页表的起始位置。
  * 每级页表条目中的地址字段包含一个 40 位物理页号(PPN)，指向下级子页表的开始处
  * 第4级页表条目中的 40 位地址字段指向物理内存中某个页的基地址。
  * 查找到 40 位物理页号结合 12位 PPO(与VPO一致)就得到物理地址 PA
* MMU 查找 TLB 的同时，L1 缓存会利用 VPO 位查找相应的组，读出组里 8 个标记和相应的数据字。
* MMU 从 TLB 或页表中得到 PPN，L1 缓存会将PPN与8个标记中数据匹配，如果有缓存对应物理地址 PA 的数据，返回结果，否则去查找 L2、L3、主存



页表条目(PTE) 有三个权限为，控制对页的访问。

* R/W 位确定页的内容是可以读写的还是只读的
* U/S位确定是否能够在用户模式中访问该页，从而保护操作系统内核中的代码和数据不被用户程序访问
* XD(禁止执行)位是 64 位系统中引入，用来禁止从某些内存页取指令，通过限制只能执行只读代码段，降低操作系统内核缓冲区溢出攻击的风险。  



当 MMU 翻译每一个虚拟地址时，还会更新另外两个内核缺页程序会用到的位。

* A位，引用位(reference bit)：每次访问一个页，MMU  会设置该位，内核可以用这个引用位来实现页替换算法。
* D位，修改位或脏位(dirty bit)：每次对一个页进行了写之后，MMU 都会设置该位，告诉内核在复制替换页之前是否必须写回牺牲页
* 内核可以通过调用特殊的内核模式指令来清除引用位或修改位



Core i7 使用四级页表翻译地址，它将 36 位 VPN 划分为 4 个 9 位的片，每个片被用作到对应一级页表的偏移量。CR3 寄存器包含 L1 页表的物理地址，VPN1 提供偏移量，这样就可以找到 L1 PTE，L1 PTE中包含 L2 页表的物理基地址，VPN2 又提供了到 L2 PTE 的偏移量，依此类推，最终 L4 PTE中包含了最终页的物理基地址。









### Linux 虚拟内存系统

Linux 为每个进程维护了一个单独的虚拟地址空间，位于进程虚拟内存(包括进程的代码、数据、堆、共享库、用户栈等)之上，称为内核虚拟内存。  

内核虚拟内存包含内核中的代码和数据结构、物理内存映射，这部分每个进程都一样。还包含每个进程都不相同的数据区域，例如页表、内核在进程上下文中执行代码时使用的栈，以及记录虚拟地址空间当前组织的各种数据结构。  



#### Linux 虚拟内存区域

Linux 将虚拟内存组织成一些区域（也叫做段）的集合。一个区域（area）就是已经存在着的（已分配的）虚拟内存的连续片（chunk），这些页以某种方式相关联。  

内核为每个进程维护一个单独的任务结构（task_struct）。任务结构中的元素包含或者指向内核运行该进程所需要的所有信息（例如 PID、指向用户栈的指针、可执行目标文件的名字、程序计数器等），其中有一个条目指向 mm_struct，它描述了虚拟内存的当前状态。  

mm_struct 的字段中有两个字段是 pgd 和 mmap，pgd 指向第一级页表(页全局目录)的基址，mmap 指向一个 vm_area_structs(区域结构)的链表，其中每个 vm_area_structs 都描述了当前虚拟地址空间的一个区域。当内核运行这个进程时，就将 pgd 存放在 CR3 控制寄存器中。具体区域的 vm_area_structs 包含：

* vm_start：区域的起始处
* vm_end：区域的结束处
* vm_prot：描述区域内包含的所有页的读写许可权限
* vm_flags：描述这个区域内的页面是与其他进程共享的，还是这个进程私有的，以及其它信息
* vm_next：链表中下一个 vm_area_structs



#### Linux 缺页异常处理

假设 MMU 在试图翻译某个虚拟地址 A 时，触发了一个缺页，这个异常导致控制转移到内核的缺页处理程序，处理程序执行如下步骤：

* 判断虚拟地址 A 是否合法，这个虚拟地址是否在某个 vm_area_structs 定义的区域内
  * 缺页处理程序搜索 vm_area_structs 的链表，把 A 和每个 vm_area_structs 中的 vm_start 、vm_end 作比较，如果指令不合法，缺页处理程序就触发一个段错误，终止这个进程。
  * 由于一个进程可以创建任意数量的新 vm_area_structs，顺序搜索这些区域结构花销可能很大，Linux 在链表中构建了一棵树，并在树上进行查找
* 判断进行的内存访问是否合法，进程是否有读、写或者执行这个区域内页面的权限，例如；
  * 缺页是否由一条试图对代码段中只读页面进行写操作存储指令造成的？
  * 缺页是否由于一个运行在用户模式进程试图从内核虚拟内存中读取字造成的？
  * 如果是不合法，去也处理程序会触发一个保护异常，终止这个进程
* 排除上述情况，内核可以确定是合法操作，继续处理缺页处理流程：
  * 选择一个牺牲页面，如果牺牲页被修改过，就将牺牲页交换出去，换入新的页面并更新页表。
  * 返回，CPU 重新启动指令，发送 A 地址到 MMU 进行翻译









## 内存映射



Linux 通过将一个虚拟内存区域与磁盘上的对象（object）关联起来，以初始化这个虚拟内存区域的内容，这个过程称为__内存映射(Memory Mapping)__。虚拟内存区域可以映射到两种类型的对象中的一种：

* Linux 文件系统中的普通文件：一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行文件。
  * 文件区（section）被分成页大小的片，每一片包含一个虚拟页面的初始内容。
  * 按需进行页面调度，虚拟页面没有实际交换进入物理内存，直到 CPU 第一次引用到页面（即发射一个虚拟地址，落在地址空间这个页面的范围之内）。
  * 如果区域比文件区要大，那么就用零来填充这个区域的余下部分。
* 匿名文件：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的全是二进制零。
  * CPU 第一次引用这样一个区域内的虚拟页面时，内核就在物理内存中找到一个合适的牺牲页面，如果该页面被修改过，就将这个页面换出来，用二进制零覆盖牺牲页面并更新页表，将这个页面标记为是驻留在内存中的。
  * 磁盘和内存之间并没有实际的数据传送。
  * 映射到匿名文件的区域的页面有时也叫做__请求二进制零的页(demand-zero page)__。

一旦一个虚拟页面被初始化了，他就在一个由内核维护的专门的__交换文件(swap file)__之间换来换去。交换文件也叫做__交换空间(swap space)__或者__交换区域(swap area)__。任何时刻，交换空间都限制这当前运行着的进程能够分配的虚拟页面的总数。



### 再看共享对象

一个对象可以被映射到虚拟内存中的一个区域，要么作为__共享对象__，要么作为__私有对象__。如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内，那么这个进程对这个区域的任何写操作，对于其他将这个共享对象映射到自己虚拟内存的进程而言，也是可见的。而且这些变化会反映在磁盘的原始对象中。  

* 对于映射到私有对象的区域做的改变，对于其他进程来说是不可见的。并且进程对这个区域所作的任何写操作不会反映在磁盘上的对象中。

* 一个映射到共享对象的虚拟内存区域叫做共享区域。类似地，也有私有区域。
* 因为每个对象都有一个唯一的文件名，内核可以迅速判定是否有进程已经映射了这个对象，后续的进程如果再次映射这个对象，直接将映射指向对应物理页面即可。这样即使存在多个映射到同一个对象，物理内存也只用存放共享对象的一个副本。
* 私有对象使用一种叫做__写时复制(copy on write)__的技术被映射到虚拟内存中
  * 私有对象开始生命周期的方式基本和共享对象一样，物理内存中之保存一份副本
  * 当多个进程映射同一个私有对象到自己的虚拟内存时，共享同一个物理内存副本
  * 相应私有区域的页表条目都被标记为只读，并且区域结构被标记为__私有的写时复制__
  * 只要有一个进程试图写私有保护区域，就会触发一个保护故障
  * 故障处理程序会判断保护异常是由于进程试图写私有的写时复制区域中的一个页面引起，它会在物理内存中创建这个页面的一个副本，更新页表条目指向这个新的副本，恢复这个页面的可写权限。
  * 故障处理程序返回时，CPU 重新执行这个写操作，就可以在新页面上正常执行。



通过延迟私有对象中的副本直到最后可能的时刻，写时复制充分利用了稀有的物理内存。





### 再看 fork 函数

当 fork 函数被当前进程调用时，内核为新进程创建各种数据结构，分配唯一的PID，新旧进程共享mm_struct、区域结构、页表等，并将两个进程中的每个页面都标记为只读，并将每个区域都标记为私有写时复制。  

当两个进程中的任何一个进行写操作时，写时复制机制会创建新页面，因此，就为每个进程保持了私有地址空间的抽象概念。





### 再看 execve 函数

execve 函数加载并运行可执行目标文件，这里假设是 a.out ，用 a.out 替代当前程序。加载并运行 a.out  需要以下步骤：

* 删除已存在的用户区域。删除当前进程虚拟地址的用户部分中已存在的区域结构。
* 映射私有区域。为新程序的代码、数据、bss、栈创建新的区域结构。
  * 所有这些新的区域都是私有的、写时复制的
  * 代码和数据区域被映射为 a.out 文件中的 .text 和 .data 区
  * bss 区域是请求二进制零的，映射到匿名文件，大小包含在 a.out 中
  * 栈和堆区域也是请求二进制零的，初始长度为零。
* 映射共享区域。如果 a.out 程序与共享对象链接，例如 libc.so，那么这些对象是动态链接到这个程序的，然后再映射到用户虚拟地址空间中的共享区域内。
* 设置程序计数器（PC）。execve 做的最后一件事就是设置当前进程上下文中的程序计数器，使之指向程序代码区域的入口点。







### 使用 mmap 函数的用户级内存映射

Linux 进程可以使用 mmap 函数来创建新的虚拟内存区域，并将对象映射到这些区域

```c
#include <unistd.h>
#include <sys/mman.h>

void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);
```



参数：

* start：仅仅是一个暗示，通常定义为 NULL
* length：连续的对象片大小
* prot：访问权限位
  * PROT_EXEC：此区域内页面可以被 CPU 执行的指令组成
  * PROT_READ：这个区域的页面可读
  * PROT_WRITE：这个区域的页面可写
  * PROT_NONE：这个区域的页面不能被访问
* flags：标志位
  * MAP_ANON：匿名对象，相应的虚拟页面是请求二进制零
  * MAP_PRIVATE：被映射的对象是私有的、写时复制的
  * MAP_SHARED：共享对象
* fd：文件描述符
* offset：偏移量，距离文件开始 offset 字节的地方







例如，让内核创建一个新的包含 size 字节的只读、私有、请求二进制零的虚拟内存区域，如果调用成功，那么 bufp 包含新区域的地址：

```c
bufp = Mmap(NULL, size, PROT_READ, MAP_PRIVATE|MAP_ANON, 0, 0);
```



munmap 函数删除虚拟内存的区域：

```c
#include <unistd.h>
#include <sys/mman.h>

int munmap(void *start, size_t length);
```

munmap 函数删除从虚拟地址 start 开始的，由接下来 length 字节组成的区域。接下来对已删除区域的引用会导致段错误。  





练习题示例，拷贝一个文件到标准输出：

```c
#include <unistd.h>
#include <sys/mman.h>
#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>


int main(int argc, char *argv[]){

    if (argc != 2)
    {
        printf("Usage: %s <file>\n", argv[0]);
        exit(0);
    }
    

    // get a file descriptor
    int fd = open(argv[1], O_RDONLY, 0);



    char *bufp;
    bufp = mmap(NULL, 4096, PROT_READ, MAP_PRIVATE, fd, 0);

    write(1, bufp, 4096);

}
```









## 动态内存分配

__动态内存分配器__(dynamic memory allocator)相比低级别的 mmap、munmap 会更方便，也更好移植。  

动态内存分配器维护着一个进程的虚拟内存区，称为__堆(heap)__。紧邻在未初始化的数据区域 .bss 后开始，向上生长（地址从低向高增长），对于每个进程，内核维护着一个变量 brk （读作 break），指向堆的顶部。  

分配器将堆视为一组不同大小的块(block)的集合来维护。每个块就是一个连续的虚拟内存片(chunk)，要么是已分配的，要么是空闲的。

* 已分配的块显式地保留为供应用程序使用，直到它显式地被应用所释放，或者是内存分配器隐式地释放
* 空闲块可以用来分配



分配器有两种基本风格，它们都要求应用显式地分配块，区别在于释放回收时由哪个实体负责：

* 显式分配器(explicit allocator)，要求显式地释放任何已分配地块。例如 C 标准库提供地 malloc 函数显式分配一个块，free 函数显式释放一个块，C++ 中地 new、delete
* 隐式分配器(implicit allocator)，也叫做垃圾收集器(garbage collector)，要求分配器检测一个已分配块何时不再被程序所使用，释放这个块。自动释放未使用的已分配的块的过程叫做垃圾收集（garbage collection），例如 Lisp、ML、Java 之类的高级语言就依赖垃圾收集释放已分配的块



### malloc 和 free 函数

C 标准库提供了一个称为 malloc 程序包的显式分配器，程序通过调用 malloc 函数来从堆中分配块。

malloc：

```c
#include <stdlib.h>

void *malloc(size_t size);
```

malloc 返回一个指针，指向大小为至少 size 字节的内存块，这个块会为可能包含在这个块内的任何数据对象类型做对齐。对齐依赖于编译在 32 位还是 64 位模式中，32为模式，返回总是8的倍数，64位返回总是16的倍数。   

* 如果 malloc 遇到问题，返回 NULL，并设置 errno
* malloc 不初始化分配的内存
* 想要初始化内存，可以调用 calloc ，这是 malloc 的瘦包装函数，将分配的内存初始化为零
* realloc 函数可以改变已分配块的大小







sbrk：

```c
#include <stdlib.h>

void *sbrk(intptr_t incr);
```

sbrk 函数通过将内核的 brk 指针增加 incr 来扩展和收缩堆。

* 如果成功，它就返回 brk 的旧值，否则就返回 -1，并将 errno 设置为 ENOMEM。
* 如果 incr 为 0，就返回 brk 当前的值。
* 用一个为负的 incr 调用 sbrk 是合法的，返回值(brk 的旧值)指向距新堆顶向上 abs(incr) 字节处





free：

```c
#include <stdlib.h>

void free(void *ptr);
```

程序通过调用 free 函数来释放已分配的堆块。ptr 参数必须指向一个从 malloc、calloc、realloc 获得的已分配块的起始位置。如果不是，那么 free 的行为就是未定义的。



### 为什么要使用动态内存分配

主要原因是，经常直到程序实际运行时，才直到某些数据结构的大小。





### 分配器的要求和目标

#### 要求

* 处理任意请求序列
  * 一个应用可以有任意的分配请求和释放请求序列，只要满足约束条件：
    * 每个释放请求必须对应于一个当前已分配的块
    * 分配器不可以假设分配和释放请求的顺序
* 立即响应请求，不允许分配器为了提高性能冲洗你排列或者缓冲请求
* 只使用堆。为了使分配器是可扩展的，分配器使用的任何非标量的数据结构都必须保存在堆里。
* 对齐块。分配器必须对齐块，使得它们可以保存任何类型的数据对象。
* 不修改已分配的块。分配器只能操作或者改变空闲块。特别是一但块被分配了，就不允许修改或者移动它了。因此诸如压缩已分配块之类的技术不允许使用。



#### 目标

在这些限制条件下，分配器编写者试图实现吞吐率最大化和内存利用率最大化，这两个性能目标通常是相互冲突的。

* 最大化吞吐率。吞吐率的定义为每个单位时间内完成的请求数。
  * 例如分配器在1秒内完成500个请求和500个释放请求，它的吞吐率为 1000次/秒
  * 一个合理性能的分配器，分配请求的最糟糕运行时间与空闲块的数量成线性关系，释放请求的运行时间是一个常数
* 最大化内存利用率。不能假设虚拟内存是无限的资源，一个系统中被所有进程分配的虚拟内存的全部数量受磁盘上交换空间的数量限制。



__峰值利用率(peak utilization)__ ：给定一个 n 个分配和释放请求的某种序列：
$$
R_0,R_1,\cdot\cdot\cdot,R_k,\cdot\cdot\cdot,R_{n-1}
$$

* 如果一个应用程序请求一个 p 字节的块，那么得到已分配的块的__有效载荷(payload)__是 p 字节
* 在请求 $R_k$ 完成之后，__聚集有效载荷(aggregate payload)__ 表示为 $P_k$，为当前已分配的块的有效载荷之和
* $H_k$ 表示堆的当前的(单调非递减的)大小
* 前 k+1 个请求的峰值利用率，表示为 $U_k$ 

公式如下：
$$
U_k = \dfrac {max_{i\le k}P_i} {H_k}
$$
分配器的目标就是在整个序列中使峰值利用率 $U_{n-1}$ 最大化。

 



### 碎片

造成堆利用率很低的主要原因是一种称为__碎片(fragmentation)__ 的现象，当虽然有未使用的内存但不能用来满足分配请求时，就发生这种现象。有两种形式：

* 内部碎片：已分配块比有效载荷大
* 外部碎片：当空闲内存合计起来足够满足一个分配请求，但没有一个空闲块足够大可以来处理这个请求。





### 实现问题

假设一个最简单的分配器，把堆组织成一个大的字节数组，还有一个指针 p，初始指向这个数组的第一个字节。为了分配 size 个字节，malloc 将 p 的当前值保存在栈里，将 p 增加 size，并将 p 的旧值返回到调用函数。free 只是简单地返回到调用函数。  

这个简单地分配器是设计中地一种极端情况。每个 malloc 和 free 只执行很少量的指令，吞吐率极好，但由于从不重复使用任何块，内存利用率将极差。一个实际的分配器要平衡吞吐率和利用率，需要考虑几个问题：

* 空闲块组织：如何记录空闲块
* 放置：如何选择一个合适的空闲块来放置一个新分配的块
* 分割：将一个新分配的块放置到某个空闲块之后，如何处理这个空闲块中剩余部分
* 合并：如何处理一个刚被释放的块



### 隐式空闲链表

任何实际的分配器都需要一些数据结构，允许它来区别块边界，以及区别已分配块和空闲块。大多数分配器将这些信息嵌入块本身。  

![image-20250912113518312](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912113518312.png)

书中示例了一个简单的方法：一个块由一个字的头部、有效载荷，以及可能的一些额外的填充组成的。头部编码了这个块的大小，以及这个块是否已分配。如果加一个双字(这里是8字节)的对齐约束条件，块大小就总是8的倍数，且块大小的最低3位总是零。因此只需要内存大小的29个高位，低位3位可以编码其他信息。这里用最低位指明这个块是已分配的还是空闲的。  

```
一个已分配的块，大小为24字节(0x18)，它的头部是：
0x00000018 | 0x1 = 0x00000019
一个空闲块，大小为40字节(0x28)，它的头部是：
0x00000028 | 0x0 = 0x00000028
```

头部后面就是应用调用 malloc 时请求的有效载荷。有效载荷后面是一片不使用的填充块，大小可以是任意的。填充的原因可以有很多，例如分配器策略用来处理外部碎片，或者满足对齐要求。  

![image-20250912113610914](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912113610914.png)

隐式空闲链表，是因为空闲块通过头部中的大小字段隐含地连接着地。分配器可以通过遍历堆中所有的块，从而间接遍历整个空闲块的集合。

隐式空闲链表的优点是简单。显著缺点是任何操作的开销，例如放置分配的块，要求堆空闲链表进行搜索，搜索所需时间和堆中已分配块、空闲块的总数呈线性关系。  

系统对齐要求和分配器堆块格式的选择，会对分配器上的最小块大小有强制要求。没有已分配块或者空闲块可以比这个最小值还小。



### 放置已分配的块

当一个应用请求一个 k 字节的块时，分配器搜索空闲链表，查找一个足够大可以放置所请求块的空闲块。分配器执行这种搜索的方式是由__放置策略(placement policy)__确定的。

常见的放置策略有：

* 首次适配（first fit）：从头开始搜索空闲链表，选择第一个合适的空闲块。
  * 优点：趋向于将大的空闲块保留在链表后面
  * 缺点：趋向于在靠近链表起始处留下小空闲块的碎片，增加了对较大块的搜索时间
* 下一次适配（next fit）：从上一次查询结束的地方开始，选择第一个合适的空闲块。
  * 优点：比首次适配运行明显快
  * 缺点：利用率要比首次适配低很多
* 最佳适配（best fit）：检查每个空闲块，选择适合所需请求大小的最小空闲块。
  * 优点：利用率高
  * 缺点：对堆要进行彻底搜索



还有一些更加精细复杂的分离式空闲链表组织，接近于最佳适配策略，但不需要进行彻底的堆搜索。





### 分割空闲块

一旦分配器找到一个匹配的空闲块，它就必须做另一个策略决定，分配这个空闲块中多少空间。

* 选择用整个空闲块：简单快捷，但是会造成内部碎片，如果放置策略趋向于产生好的匹配，内部碎片是可以接受的
* 选择分割：将这个空闲块分割为两部分，一部分变为分配快，剩下的变成一个新的空闲块。

![image-20250912113628616](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912113628616.png)



### 获取额外的堆内存

如果分配器不能为请求块找到合适的空闲块：

* 一个选择是合并那些在内存中物理上相邻的空闲块来创建一些更大的空闲块
* 如果已经最大程度合并了，分配器就会调用 sbrk 函数，向内核请求额外的堆内存，分配器将额外的内存转化成一个大的空闲块，插入到空闲链表中，再分配请求块



### 合并空闲块

当分配器释放一个已分配块时，可能有其他空闲块和这个新释放的空闲块相邻，这些邻接的空闲块可能引起一种现象，叫做__假碎片(fault fragmentation)__，就是可能有许多可用的空闲块被切割成为小的、无法使用的空闲块。  

为解决假碎片问题，任何实际的分配器都必须和并相邻的空闲块，这个过程被称为__合并(coalescing)__，合并的时机也是一个重要的决策：

* 立即合并：每次一个块被释放时，就合并所有的相邻块
  * 简单明了
  * 某些请求模式下，会产生抖动，块会被反复合并，然后马上分割
* 推迟合并：可以定时或者等到某个分配请求失败，然后再扫描堆，合并现有的空闲块



![image-20250912113649577](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912113649577.png)



### 带边界标记的合并



将当前块的头部指向下一个块的头部，检查这个指针以判断下一个块是否时空闲的，如果是，九江它的大小简单地加到当前块头部的大小上，这两个块在常数时间内被合并。  

如果合并前面的块，在带头部的隐式空闲链表中，只能选择搜索整个链表，记住前面块的位置，直到到达当前块。因此使用隐式空闲链表，每次调用 free 需要的时间都与堆的大小成线性关系，搜索时间不会是常数。   

  

Knuth 提出一种技术叫做 __边界标记(boundary tag)__，允许在常数时间内进行对前面块的合并：在每个块的结尾处添加一个 __脚部(footer,边界标记)__ ，脚部就是头部的一个副本。每个块都包括这样一个脚部，分配器可以通过检查脚部，判断前面一个块的起始位置和状态，这个脚部总是在距当前块开始位置一个字的距离。  

分配器释放当前块时可能存在的情况：

1. 前面的块和后面的块都是已分配的
   * 无法合并，只是简单地将当前块从已分配变成分配
2. 前面的块是已分配的，后面的块是空闲的
   * 当前块与后面的块合并，用当前块和后面块大小的和来更新当前块的头部和后面块的脚部
3. 前面的块是空闲的，后面的块是已分配的
   * 前面的块与当前块合并，用前面的块和当前块大小的和来更新前面块的头部和当前块的脚部
4. 前面的和后面的块都是空闲的
   * 合并三个块，用三个块的大小之和来更新前面块的头部和后面块的脚部。



![image-20250912113746394](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912113746394.png)



这几种情况中合并都是在常数时间内完成的。但边界标记也有一个潜在的缺陷，它要求每个块保持一个头部和一个脚部，应用程序在操作许多个小块时，会产生显著的内存开销。例如图形应用反复调用 malloc、free 动态创建和销毁图形节点，每个节点只要两个内存字，头部和脚部将会占用每个已分配块一半的空间。  

优化方法：将前面块的已分配/空闲位存放在当前块中多出来的低位中，这样只有空闲块需要脚部，已分配块不需要脚部。







### 综合：实现一个简单的分配器

基于隐式空闲链表，使用立即边界合并方式，实现一个简单分配器。最大的块大小为 $2^{32}=4GB$ ，代码是 64 位干净的，即代码能不加修改地运行在32位(gcc -m32)和64位(gcc -m64)地进程中。 



#### 通用分配器设计

memlib.c 提供一个内存系统模型，目的在于允许不干涉已存在地系统层 malloc 包地情况下，运行分配器。

```c
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
#include <unistd.h>
#include <sys/mman.h>
#include <string.h>
#include <errno.h>

#include "config.h"

// 起始位置
static char *mem_heap;
// 堆顶
static char *mem_brk;
// 堆最大可用地址
static char *mem_max_addr;

// 初始化，malloc分配内存块，mem_heap、mem_brk都指向堆的起始位置
void mem_init(){
    mem_heap = (char *)malloc(MAX_HEAP);
    mem_brk = (char *)mem_heap;
    mem_max_addr = (char *)(mem_heap + MAX_HEAP);
}

// mem_brk 增长 incr，返回旧的堆顶指针地址
void *mem_sbrk(int incr){
    char *old_brk = mem_brk;

    if((incr < 0) || ((mem_brk + incr) > mem_max_addr)){
        errno = ENOMEM;
        fprintf(stderr, "ERROR: mem_sbrk failed. out of memory\n");
        return (void *)-1;
    }
    mem_brk += incr;
    return (void *)old_brk;
}
```

mem_init 函数将对于堆来说可用地虚拟内存模型化为一个大的、双字对齐的字节数组。mem_heap 和 mem_brk 之间属于已分配的虚拟内存，mem_brk 之后的字节表示未分配的虚拟内存。分配器通过调用 mem_sbrk 来请求额外的堆内存。  







隐式空闲链表有着恒定形式：

* 第一个字是一个双字边界对齐的不使用的填充字
* 填充后面紧跟着一个特殊的__序言块(prologue block)__，8字节，由头部和脚部组成
* 序言块后面是0个或多个由 malloc 、free 调用的普通块
* 以一个特殊的__结尾块(epilogue block)__来结束，由一个头部组成
* 分配器使用一个私有(static)全局变量 heap_listp 指向序言块(这里做了优化，指向序言块的下一个块，即序言块脚部)

 ![image-20250912113817145](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912113817145.png)





#### 操作空闲链表的基本常数和宏



```c
/*** 基本常数 ***/
// WSIZE 是字大小(byte)，DSIZE是双字大小，CHUNKSIZE 用来扩展堆
#define WSIZE 4
#define DSIZE 8
#define CHUNKSIZE (1<<12)

/*** 宏 主要用来访问和遍历空闲链表 ***/
// 比大小
#define MAX(x, y) ((x) > (y) ? (x) : (y))

// 将大小和已分配位结合，返回一个值，可以把这个值放在头部或脚部
#define PACK(size, alloc) ((size) | (alloc))

// 从地址p处，读取或者写入一个字(word)大小的值，参数 p 是一个(void *)类型的指针，不能进行间接引用，因此必须要强制转换为(unsigned int *)
#define GET(p)  		(*(unsigned int *)(p))
#define PUT(p, val) 	(*(unsigned int *)(p) = (val))

// 获取大小和已分配位，&~0x7 表示忽略低3位取高位代表块大小的值，&0x1 表示获取最低位(代表分配位)
#define GET_SIZE(p)		(GET(p) & ~0x7)
#define GET_ALLOC(p)	(GET(p) & 0x1)


// 根据块指针 bp (block pointer的简写)，计算头部和脚部的地址
// bp指向可用地址，-WSIZE为头部地址
#define HDRP(bp)		((char *)(bp) - WSIZE)
// 获取块大小，再 -DSIZE 减去脚部大小后就是脚部的起始地址
#define FTRP(bp)		((char *)(bp) + GET_SIZE(HDRP(bp)) - DSIZE)

// 根据块指针 bp，计算下一个块、前一个块的地址
// ((char *)(bp) - WSIZE)是头部地址，GET_SIZE 获取到块大小，当前块指针bp加上块大小，就是下一个块有效载荷指针地址
#define NEXT_BLKP(bp)	((char *)(bp) + GET_SIZE(((char *)(bp) - WSIZE )))
// 头部和脚部内容一样，((char *)(bp) - DSIZE)得到前一个块的脚部，GET_SIZE获取到前一个块大小，当前块bp减去前一个块的大小，就是前一个块的有效载荷地址
#define PREV_BLKP(bp)	((char *)(bp) - GET_SIZE(((char *)(bp) - DSIZE )))

// 堆起始位置指针
static char *heap_listp;


```

使用示例：

```c
// 给定一个当前块指针 bp，确定内存中后面块的大小
size_t size = GET_SIZE(HDRP(NEXT_BLKP(bp)));
```



#### 创建初始空闲链表



```c
// 初始化堆
int mm_init(void){
    // 获取4个字的内存，heap_listp 指向起始位
    if ((heap_listp = mem_sbrk(4*WSIZE)) == (void *)-1)
        return -1;
    // 填充第一个字(4字节，32位)为0
    PUT(heap_listp, 0);
    // 第二个字开始放 序言块 prologue 头部
    PUT(heap_listp + (1*WSIZE), PACK(DSIZE, 1));
    // 第三个字开始放 序言块 prologue 脚部
    PUT(heap_listp + (2*WSIZE), PACK(DSIZE, 1));
    // 第四个字开始放 结尾块 epilogue 头部
    PUT(heap_listp + (3*WSIZE), PACK(0, 1));
    // 将 heap_listp 指向序言块 prologue 脚部
    heap_listp += (2*WSIZE);
    
    // 扩展空的堆 CHUNKSIZE 字节，创建初始空闲块
    if (extend_heap(CHUNKSIZE/WSIZE) == NULL)
        return -1;
    return 0;
}
```

mem_init 函数从内存系统获取 4 个字，并初始化这4个字，创建一个空的空闲链表。之后再调用 extend_heap 函数，扩展 CHUNKSIZE 字节，创建初始的空闲块。至此，分配器就可以接受来自应用的分配、释放请求了。





```c
// 用一个新的空闲块扩展堆
static void *extend_heap(size_t words){
    char *bp;
    size_t size;
    
    // 保持双字对齐，words参数是奇数就+1，偶数就不变
    size = (words % 2) ? (words+1) * WSIZE : words * WSIZE;
    // 如果 mem_sbrk 返回-1就返回NULL
    if ((long)(bp = mem_sbrk(size)) == -1)
        return NULL;
    
    // 初始化空闲块的头部、尾部、结尾块头部
    PUT(HDRP(bp), PACK(size, 0));
    PUT(FTRP(bp), PACK(size, 0));
    PUT(HDRP(NEXT_BLKP(bp)), PACK(0, 1));
    
    // 如果前一个块时空闲块，就合并后返回
    return coalesce(bp);
}
```

extend_heap 函数会在两种环境被调用：

1. 堆被初始化时
2. 当 mm_malloc 不能找到一个合适的匹配块时

extend_heap 返回一个双字整数倍大小的空闲块，函数中调用 mem_sbrk ，返回一个双字对齐的内存片，在结尾块的头部后面。结尾块头部就变成新的空闲块的头部，内存片最后一个字变成新的结尾块头部。最后，可能出现前一个堆以一个空闲块结束的情况，调用 coalesce 函数合并两个空闲块，返回合并后块的块指针。  



#### 释放和合并块



```c
void mm_free(void *bp){
    // 获取块大小
    size_t size = GET_SIZE(HDRP(bp));
    
    // 修改当前块的头部、脚部
    PUT(HDRP(bp), PACK(size, 0));
    PUT(FTRP(bp), PACK(size, 0));
    // 调用合并空闲块函数
    coalesce(bp);
}
```

mm_free 函数释放一个块，将所有邻接的空闲块合并



```c
static void *coalesce(void *bp){
    // 获取前、后块的分配位，1为已分配，0为未分配
    size_t prev_alloc = GET_ALLOC(FTRP(PREV_BLKP(bp)));
    size_t next_alloc = GET_ALLOC(HDRP(NEXT_BLKP(bp)));
    // 当前块大小
    size_t size = GET_SIZE(HDRP(bp));
    
    // 前后块均为1，都已分配
    if (prev_alloc && next_alloc){
        return bp;
    }
    // 前面块已分配，后面块为空闲块
    else if (prev_alloc && !next_alloc) {
        // size 变为当前块 + 后面空闲块
        size += GET_SIZE(HDRP(NEXT_BLKP(bp)));
        // 将当前块头部大小变为新的 size
        PUT(HDRP(bp),PACK(size,0));
        // 将合并后脚部大小变为新的 size
        PUT(FTRP(bp),PACK(size,0));
    }
    // 前面块为空闲块，后面块已分配
    else if (!prev_alloc && next_alloc) {
        // size 变为当前块 + 前面空闲块
        size += GET_SIZE(HDRP(PREV_BLKP(bp)));
        // 将前面空闲块头部大小变为新的 size
        PUT(HDRP(PREV_BLKP(bp)),PACK(size,0));
        // 将当前块脚部大小变为新的 size
        PUT(FTRP(bp),PACK(size,0));
        // 将指针指向合并后的新空闲块有效载荷位置
        bp = PREV_BLKP(bp);
    }
    // 前后块都为空闲块
    else {
        // size 变为当前块 + 前后空闲块
        size += GET_SIZE(HDRP(NEXT_BLKP(bp))) + GET_SIZE(HDRP(PREV_BLKP(bp)));
        // 修改前面空闲块头部
        PUT(HDRP(PREV_BLKP(bp)),PACK(size,0));
        // 修改后面空闲块脚部
        PUT(FTRP(NEXT_BLKP(bp)),PACK(size,0));
        // 修改 bp 指针
        bp = PREV_BLKP(bp);
    }
    
    return bp;
}
```

coalesce 函数实现了四种情况下的空闲块合并。  

书中示例的空闲链表格式（序言块、结尾块总是标记为已分配）允许忽略潜在的麻烦边界情况。如果没有这些特殊块，代码将混乱很多，容易出错，并且速度更慢，每次处理释放请求时，还要再检查不常见的边界情况。这是一种通过数据结构简化实现算法的高明手段。





#### 分配块

应用通过调用 mm_malloc 函数向内存请求大小为 size 字节的块，mm_malloc 需要：

* 检查请求的真假

* 调整请求块大小，从而为头部、脚部留有空间，并满足双字对齐要求

* 搜索空闲链表，寻找一个合适的空闲块

* 如果有合适的，分配器放置这个请求块，可选的分割出多余的部分，返回新分配块的地址

* 如果没有合适的块，申请一个新的空闲块来扩展堆，把请求块放置再新的空闲块里，可选的分割这个块，返回指向新分配块的指针

  

```c
void *mm_malloc(size_t size){
    size_t asize;
    size_t extendsize;
    char *bp;
    
    // 忽略 spurious(假的、伪造、错误的) 请求
    if (size == 0)
        return NULL;
    
    // 强制最小块大小为 16 字节，8字节用来满足对齐要求，8字节用来放头部、脚部
    if (size <= DSIZE)
        asize = 2*DSIZE;
    // 超过8字节的请求，加上开销字节，向上舍入到最接近8的整数倍
    else
        asize = DSIZE * ((size + (DSIZE) + (DSIZE-1)) / DSIZE);
    
    
    // 搜索空闲链表，找到合适的块
    if ((bp = find_fit(asize)) != NULL) {
        place(bp, asize);
        return bp;
    }
    
    // 没找到合适的空闲块，申请更多内存来放置块
    extendsize = MAX(asize, CHUNKSIZE);
    if ((bp = extend_heap(extendsize/WSIZE)) == NULL)
        return NULL;
    place(bp, asize);
    return bp;
    
}
```







练习 9.8 find_fit 函数实现：

```c
// 对空闲链表进行首次适配搜索
static void *find_fit(size_t asize){
    char *bp;
    size_t cur_size = 0;
    
    // 从堆起始处开始搜索
    bp = heap_listp + (1*WSIZE);
    // 检查大小，非空就进入循环
    while(GET_SIZE(HDRP(bp)){
        // 如果未分配或者大于等于asize，就返回
        if (!GET_ALLOC(HDRP(bp)) && (GET_SIZE(HDRP(bp)) >= asize))
            return bp;
        
        bp = NEXT_BLKP(bp);
    }
    
    return NULL;
}
```







练习 9.9 place 函数实现：

```c
// 将请求块放置在空闲块的起始位置，只有当剩余部分的大小等于或者超出最小块的大小(16字节)时，才进行分割
static void place(void *bp, size_t asize){
    // 获取空闲块大小
    size_t fb_size;
    fb_size = GET_SIZE(bp); 
    
    // 修改头部、脚部大小和已分配位
    // 对比要放置的请求块大小，大于等于 4 个字，进行分割
    size_t remains;
    remains = fb_size - asize;
    if (surplus >= (4*WSIZE) ) {
        PUT(HDRP(bp), PACK(asize,1));
        PUT(FTRP(bp), PACK(asize,1));
		PUT(HDRP(NEXT_BLKP(bp)), PACK(remains,0));
   		PUT(FTRP(NEXT_BLKP(bp)), PACK(remains,0));
    }
    // 小于 4 个字，全部分配给请求块
    else {
        PUT(HDRP(bp), PACK(fb_size,1));
        PUT(FTRP(bp), PACK(fb_size,1));
    }    
}

```







### 显式空闲链表

上一节中的隐式空闲链表实现简单，但块分配和堆块的总数呈线性关系，因此对于通用的分配器是不适合的。  

一种方法就是将空闲块组织位某种显式数据结构。

堆可以组织成一个双向空闲链表，在每个空闲块中，都包含一个 pred(前驱) 和 succ(后继) 指针：

![image-20250912113356577](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912113356577.png)

使用双向链表，使得首次适配的分配时间从块总数的线性时间减少到了空闲块数量的线性时间。释放一个块可能是线性的，也可能是常数，取决于空闲链表中块的排序策略。例如：

* 先进先出(LIFO)：将新释放的块放置在链表的开始处。使用 LIFO 的排序策略和首次适配的放置策略，分配器会最先检查最近使用过的块。这种情况下，释放一个块可以在常数时间内完成。
* 地址顺序：链表中每个块的地址都小于它后继的地址。这种情况下，释放一个块需要线性时间的搜索来定位合适的前驱。但内存利用率会更高，接近最佳适配的利用率。



显式空闲链表的缺点是空闲块必须足够大，以包含所有需要的指针，以及头部和可能的脚部，导致了更大的最小块，潜在提高了内部碎片的程度。





### 分离的空闲链表

使用单向空闲链表的分配器需要与空闲块数量呈线性关系的时间来分配块，有一种流行的减少分配时间的方法，称为__分离存储(segregated storage)__，就是维护多个空闲链表，其中每个链表中的块都有大致相等的大小。一般的思路是将所有可能的块大小分成一些等价类，也叫做__大小类(size class)__。  

例如，根据 2 的幂来划分块大小：

```
{1},{2},{3,4},{5 ~ 8},...,{1025 ~ 2048},{2049 ~ 4096},{4097 ~ ∞}
```

或者将小的块分派到它们自己的大小类里，iang大块按照 2 的幂分类：

```
{1},{2},{3},...,{1023},{1024},{1025 ~ 2048},{2049 ~ 4096},{4097 ~ ∞}
```

分配器维护着一个空闲链表数组，每个大小类一个空闲链表，按照大小的升序排列。当分配器需要一个大小为 n 的块时，它就搜索相应的空闲链表。如果不能找到合适的块，就搜索下一个链表，以此类推。  

有关动态内存分配的文献描述了几十种分离存储方法，主要区别在于：

* 它们如何定义大小类
* 何时进行合并
* 何时向操作系统请求额外的堆内存
* 是否允许分割
* 等等



书中描述了两种基本的方法：

* 简单分离存储(simple segregated storage)
* 分离适配(segregated fit)



####  简单分离存储

每个大小类的空闲链表包含大小相等的块，每个块的大小就是这个大小类中最大元素的大小。例如某个大小类定义为{17~32}，那么这个类的空闲链表全由大小为 32 的块组成。  

为了分配一个给定大小的块，我们检查相应的空闲链表。如果链表非空，我们简单的分配其中第一块的全部（空闲块是不会分割以满足分配请求的）。如果链表为空，分配器就向操作系统请求一个固定大小的额外内存片（通常是页大小的整数倍），将这个片分成大小相等的块，并将这些块链接起来以形成新的空闲链表。要释放一个块，分配器只要简单地将这个块插入到相应地空闲链表地前部。  

特点：

* 分配和释放块都是很快地常数时间操作
* 每个片中都是大小相等的块，不分割，不合并，内存开销少
* 每个片只有大小相同的块，已分配块的大小就可以从它的地址推断出来
* 没有合并，已分配块的头部就不需要一个已分配/空闲标记，不需要头部、脚部
* 分配和释放操作都是在空闲链表起始处，链表只需要是单向的
* 任何块都需要唯一的字段是每个空闲块中的一个字的 succ 指针，因此最小块大小就是一个字



缺点：简单分离存储容易造成内部和外部碎片，碎片数量取决于应用场景和引用模式。





#### 分离适配

这种方法，分配器维护着一个空闲链表的数组。每个空闲链表是和一个大小类相关联的，并且被组织成某种类型的显式或隐式链表。每个链表包含潜在的大小不同的块，这些块的大小是大小类的成员。有多种不同的分离适配分配器，书中这里描述了一个简单的版本：  

* 为了分配一个个块，必须确定请求的大小类，并且对适当的空闲链表做首次适配，查找一个合适的块。
* 如果找到了一个，那么就分割它(可选)，并将剩余的部分插入到适当的空闲链表中。
* 如果找不到合适的块，那么就搜索下一个更大的大小类的空闲链表，如此重复，直到找到一个合适的块。
* 如果空闲链表中没有合适的块，那么就向操作系统请求额外的堆内存，从这个新的堆内存中分配出一个块，将剩余部分放置在适当的大小类中。
* 如果要释放一个块，我们执行合并，并将结果放置到相应的空闲链表中。



C 标准库中的 GNU malloc 包就是采用这种分离适配的方法，既快速，对内存的使用率也很高。搜索被限制在堆的某个部分，而不是整个堆，因此搜索时间减少了。



#### 伙伴系统

__伙伴系统(buddy system)__ 是分离适配的一种特例，每个大小类都是 2 的次幂。

基本思路是假设一个堆的大小为 $2^m$ 个字，我们为每个块大小 $2^k$ 维护一个分离空闲链表，其中 $0\le k \le m$ 。请求块大小向上舍入到最接近 2 的幂。

* 最开始时，只有一个大小为 $2^m$ 个字的空闲块。  
* 为了分配一个大小为 $2^k$ 的块，找到一个可用的、大小为 $2^j$ 的块，其中 $k \le j \le m$。
* 如果 $j=k$ ，那么我们那就完成了。
* 否则，我们递归地二分分割这个块，直到 $j=k$ 。
* 当我们进行这样地分割时，每个剩下地半块(也叫做伙伴)被放置在相应地空闲链表中。
* 要释放一个大小为 $2^k$ 的块，我们继续合并空闲的伙伴。当遇到一个已分配的伙伴时，我们就停止合并。  

关于伙伴系统的一个关键事实是，给定地址和块的大小，很容易计算出它的伙伴的地址。例如，一个块，大小为 32 字节，地址为：
$$
xxx \cdot\cdot\cdot x00000
$$
它的伙伴的地址为：


$$
xxx \cdot\cdot\cdot x10000
$$
一个块和它的伙伴的地址只有一位不相同。  

伙伴系统分配器的主要优点是快速搜索和快速合并。主要缺点是要求块大小为 2 的幂可能导致显著的内部碎片。因此不适合通用目的的工作负载，但对于特定应用的工作负载，块大小是2的幂，伙伴系统分配器就很合适。





## 垃圾收集



### 垃圾收集基本知识

垃圾收集器将内存视为一张__有向可达图(reachability graph)__，该图的节点被分成一组__根节点(root node)__和一组__堆节点(heap node)__。每个堆节点对应于堆中的一个分配快。有向边 $p \rarr q$  意味着块 p 中的某个位置指向块 q 中的某个位置。根节点对应于不在堆中的位置，它们包含指向堆中的指针。可以是寄存器、栈里的变量、虚拟内存中读写数据区域内的全局变量。  

![image-20250912153843360](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912153843360.png)

当存在一条从任意根节点出发并到达 p 的有向路径时，我们说节点 p 是可达的(reachable)。在任何时刻，不可达节点对应于垃圾，是不能被应用再次使用的。垃圾收集器的角色是维护可达图的某种表示，并通过释放不可达节点将它们返回给空闲链表，来定期地回收它们。  

ML、Java 一类的语言，对应用如何创建和使用指针有很严格的控制，能够维护可达图的精确表示，因此能够回收所有垃圾。然而C、C++ 这一类的语言通常不能维持可达图的精确表示。这种的收集器也叫做__保守的垃圾收集器(conservative garbage collector)__，因为有些不可达节点有可能被错误地标记为可达。  

垃圾收集器可以按需提供服务，或者作为一个和应用并行的独立线程，不断地更新可达图和回收垃圾。



### Mark & Sweep 垃圾收集器

Mark&Sweep 垃圾收集器由__标记(mark)__阶段和__清除(sweep)__阶段组成，标记阶段标记出根节点的所有可达和已分配的后继，后面的清除阶段释放每个未被标记的已分配块。块头部中空闲的低位中的一位通常用来表示这个块是否被标记了。

Mark&Sweep 需要实现一些函数，书中列举如下：

* 指针 ptr 被定义为 typedef void *ptr;
* ptr isPtr(ptr p)：如果 p 是指向一个已分配块中的某个字，返回一个指向这个块的起始位置的指针 b，否则返回 NULL
* int blockMarked(ptr b)：如果块 b 是已标记的，返回 true
* int blockAllocated(ptr b)：如果块 b 是已分配的，返回 true
* void markBlock(ptr b)：标记块 b
* int length(b)：返回块 b 的长度(单位是字节，不包括头部)
* void unmarkBlock(ptr b)：将块 b 的状态修改为未标记
* ptr nextBlock(ptr b)：返回堆中 b 的后继



标记阶段函数是 mark：

```c
void mark(ptr p){
    // 如果 p 不是已分配块的指针，直接返回
    if ((b = isPtr(p)) == NULL)
        return;
    // 如果块已标记，直接返回
    if (blockMarked(b))
        return;
    // 标记这个块
    markBlock(b);
    // 获取块大小，递归的调用 mark() 函数标记块中的字
    len = length(b);
    for (i=0;i<len;i++)
        mark(b[i]);
    
    return;
    
}
```



清除阶段函数是 sweep：

```c
// 参数 b 是起始位置指针，end 是结尾
void sweep(ptr b, ptr end){
    
    while (b < end) {
        // 如果当前块已标记，就修改为未标记
        if (blockMarked(b))
            unmarkBlock(b);
        // 如果已分配，就释放当前块
        // 进入这个分支说明是未标记的块，释放未标记已分配的块
        else if (blockAllocated(b))
            free(b);
        // b 指向下一个块
        b = nextBlock(b);
    }
    return;
}
```

一个小堆的 Mark&Sweep 的图形化表示：

![image-20250912162328088](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912162328088.png)



### C程序的保守 Mark&Sweep

Mark&Sweep 对C程序的垃圾收集是一种合适的方法，可以就地工作，不需要移动任何块。然而也有一些挑战：

1. C 不会用任何类型信息来标记内存位置。因此 isPtr 函数没有一种明显的方式来判断它的输入参数 p 是不是一个指针。
2. 即使知道 p 是指针，isPtr 也没有明显的方式来判断 p 是否指向一个已分配块的有效载荷中的某个位置。

第二种问题可以将已分配块的集合维护成一颗平衡二叉树，保持着一个属性：左子树中的所有块都放在较小的地址处，右子树中的所有块都放在较大的地址处。

![image-20250912162844217](..\upload\2025-08-15-CSAPP-虚拟内存\image-20250912162844217.png)

这样就要求每个已分配块的头部里由两个附加字段（left、right），每个字段指向某个已分配块的头部。isPtr(ptr p) 函数用树来执行对已分配块的二分查找。每一步都依赖块头部中的大小字段来判断 p 是否落在这个块的范围之内。  

平衡树方法保证会标记所有从根节点可达的节点，这是一个必要的保证，不会过早的释放应用申请的已分配块。但因此可能不会释放某些垃圾，不影响正确性，但可能导致不必要的外部碎片。  

C 程序的 Mark&Sweep 收集器必须是保守的，根本原因是 C 语言不会用类型信息来标记内存位置。因此，像 int 或者 float 这样的标量可以伪装成指针。例如某个可达的已分配块，在它的有效载荷中包含一个 int，其值恰好对应于某个其他已分配块 b 的有效载荷中的一个地址，对于收集器无法判断出这个数据是 int 而不是指针。因此，分配器必须保守的标记块 b 可达。



## C程序中常见的与内存相关的错误



### 间接引用坏指针



```c
// 用 scanf 从 stdin 读一个整数到变量
scanf("%d", &val);

// 参数不小心写成了内容，而不是地址
// scanf 会尝试把 val 的内容解释为一个地址，并试图将一个字写道这个位置，最好的情况下，程序异常终止，在最糟糕的情况下，val 的内容对应于虚拟内存中某个合法的读/写区域，于是就覆盖了这块内存。
scanf("%d", val);


```





### 读未初始化的内存



```c
int *matvec(int **A, int *x, int n){
    int i, j;
    
    int *y = (int *)Malloc(n * sizeof(int));
    
    for ( i=0 ; i<n ; i++){
        for (j=0;j<n;j++)
            y[i] += A[i][j] * x[j];
    }
    return y;
}

```

这里假设向量 y 被初始化为零，正确的实现是显式地将 y[i] 设置为零，或者使用 calloc。



### 允许栈缓冲区溢出



```c
void bufoverflow(){
    char buf[64];
    
    gets(buf);
    return;
}
```

未检查输入串大小就写入栈中的目标缓冲区，就会由缓冲区溢出错误(buffer overflow bug)。这里 gets 函数复制一个任意长度的串到缓冲区，可以修改为 fgets 函数，该函数限制了输入串的大小。



### 假设指针和它们指向的对象是相同大小的



```c
int **makeArray1(int n, int m){
    int i;
    int **A = (int **)Malloc(n * sizeof(int));
    
    for (i=0;i<n;i++)
        A[i] = (int *)Malloc(m * sizeof(int));
    
    return A;
}
```

这里函数的目的是创建一个由 n 个指针组成的数组，每个指针都指向一个包含 m 个 int 的数组。但第三行将 sizeof(int *) 写成了 sizeof(int)，实际上创建的是一个 int 数组。  

这个函数只有在 int 和指向 int 的指针大小相同的机器上运行良好。如果像 Core i7 这种机器上，指针大于 int，那么 for 循环将写到超出 A 数组结尾的地方。这些字很可能是已分配块的边界标记脚部，错误不会被发现，直到程序在后面释放这个块时，分配器中的合并代码将失败。



### 造成错位错误

错位(off-by-one)错误时一种常见的造成覆盖错误的来源：

```c
int **makeArray2(int n, int m){
    int i;
    int **A = (int **)Malloc(n * sizeof(int *));
    
    for (i=0;i<=n;i++)
        A[i] = (int *)Malloc(m * sizeof(int));
    
    return A;
}
```

这里for循环试图初始化这个数组的 n+1 个元素，覆盖了 A 数组后面的某个内存位置。





### 引用指针，而不是它所指向的对象

下面函数目的是删除一个有 *size 项的二叉堆里的第一项，然后对剩下的 *size-1 项重新建堆：

```c
int *binheapDelete(int **binheap, int *size){
    int *packet = binheap[0];
    
    binheap[0] = binheap[*size -1];
    *size--;
    heapify(binheap, *size, 0);
    return(packet);
}
```

其中 `*size--;` 这一行的目的是减少指针指向的整数的值，由于一元运算符 `--` 和 `*` 的优先级相同，从右向左结合，所以实际是减少的是指针自己的值，而不是所指向整数的值。如果幸运的话，程序会立即失败；但是更有可能的是执行很久，产生一个不正确的结果时，才被发现。  

可以使用括号，清晰表达意图，`(*size)--;`，避免这种情况。





### 误解指针运算

一种常见的错误是忘记指针的算数操作是以它们指向的对象的大小为单位来进行的，而这种大小单位并不一定是字节。这函数的目的是扫描一个 int 数组，并返回一个指针，指向 val 首次出现的位置：

```c
int *search(int *p, int val){
    while (*p && *p != val)
        p += sizeof(int);  /* should be p++ */
    
    return p;
}
```

但每次循环时，把指针加了 4 （一个整数的字节数），函数就不正确的扫描数组中每 4 个整数。



### 引用不存在的变量



```c
int *stackref(){
    int val;
    
    return &val;
}
```

这里返回一个指针，指向栈里的一个局部变量，然后弹出栈帧。尽管指针仍指向合法的内存地址，但已经不是一个合法变量，后面程序中调用其他函数，内存将重用它们的栈帧，再后来如果程序分配某个值给这个指针，可能实际上在修改另一个函数的栈帧的条目，从而引发灾难、令人迷惑的结果。



### 引用空闲堆块中的数据



```c
int *heapref(int n, int m){
    int i;
    int *x, *y;
    
    x = (int *)Malloc(n * sizeof(int));
    
    // Other calls to malloc and free go here
    
    free(x);
    
    y = (int *)Malloc(m * sizeof(int));
    for (i=0;i<m;i++)
        y[i] = x[i]++;  //  x[i] 是一个空闲块中的字
    
    return y;
}
```

这个函数中先分配了一个整数数组 x，然后执行一些 malloc 、free 调用后，又释放了 x，但之后又引用了 x[i] 为 y[i] 赋值，但此时 x 可能已经被其他已分配堆块使用，内容被重写，直到发现 y 中的值被错误修改才能发现异常。





### 引起内存泄漏



```c
void leadk(int n){
    int *x = (int *)Malloc(n * sizeof(int));
    
    return;
}
```

这里分配了一个堆块 x，没有释放已分配块就返回。如果经常调用 leak，渐渐的堆里就充满了垃圾，最糟糕情况下会占用整个虚拟地址空间。尤其像守护进程和服务器一类的程序，内存泄漏特别严重，因为这些程序一般是不会终止的。